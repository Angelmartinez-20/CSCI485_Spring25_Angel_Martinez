{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf8a3c62-216c-446d-851d-7249cc67787a",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {align:left;display:block} \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {align:left;display:block} \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e27c8c-7f53-4e9f-b4da-7e0343fb6313",
   "metadata": {},
   "source": [
    "# Markov Decision Process (MDP)\n",
    "----\n",
    "\n",
    "**Value Iteration Process with Policy Changes in MDP**\n",
    "\n",
    "We begin with a Markov Decision Process (MDP) where an agent decides whether to invest conservatively (C) or aggressively (A) in a financial portfolio. The objective is to find an optimal policy maximizing long-term rewards.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Defining the MDP Components**\n",
    "\n",
    "**States (S):**\n",
    "\n",
    "- Low Wealth (L)\n",
    "- Medium Wealth (M)\n",
    "- High Wealth (H)\n",
    "\n",
    "**Actions (A):**\n",
    "\n",
    "- Conservative (C)\n",
    "- Aggressive (A)\n",
    "\n",
    "**Transition Probabilities:**\n",
    "\n",
    "| Current State | Action | Next State Probabilities     |\n",
    "| ------------- | ------ | ---------------------------- |\n",
    "| Low (L)       | C      | 80% Stay in L, 20% Move to M |\n",
    "| Low (L)       | A      | 60% Stay in L, 40% Move to M |\n",
    "| Medium (M)    | C      | 70% Stay in M, 30% Move to H |\n",
    "| Medium (M)    | A      | 50% Stay in M, 50% Move to H |\n",
    "| High (H)      | C      | 90% Stay in H, 10% Drop to M |\n",
    "| High (H)      | A      | 70% Stay in H, 30% Drop to M |\n",
    "\n",
    "**Rewards:**\n",
    "\n",
    "- Low Wealth (L): -1\n",
    "- Medium Wealth (M): 3\n",
    "- High Wealth (H): 5\n",
    "\n",
    "**Discount Factor (γ):** 0.9\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7717db5",
   "metadata": {},
   "source": [
    "### **Step 2: Value Iteration Updates**\n",
    "\n",
    "We initialize values: $V_0(L) = 0$, $V_0(M) = 0$, $V_0(H) = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e24e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v0_L = 0\n",
    "v0_M = 0\n",
    "v0_H = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa94cb3",
   "metadata": {},
   "source": [
    "#### **Iteration 1**\n",
    "\n",
    "Using Bellman’s equation:\n",
    "\n",
    ">$$\n",
    "V_1(s) = \\max_a \\left[ R(s) + \\gamma \\sum_{s'} P(s' | s, a) V_0(s') \\right]\n",
    "$$\n",
    "\n",
    "For **Low Wealth (L):**\n",
    "\n",
    ">$$\n",
    "V_1(L) = \\max \\left[ -1 + 0.9(0.8V_0(L) + 0.2V_0(M)), -1 + 0.9(0.6V_0(L) + 0.4V_0(M)) \\right]\n",
    "$$\n",
    "\n",
    "For **Medium Wealth (M):**\n",
    "\n",
    ">$$\n",
    "V_1(M) = \\max \\left[ 3 + 0.9(0.7V_0(M) + 0.3V_0(H)), 3 + 0.9(0.5V_0(M) + 0.5V_0(H)) \\right]\n",
    "$$\n",
    "\n",
    "For **High Wealth (H):**\n",
    "\n",
    ">$$\n",
    "V_1(H) = \\max \\left[ 5 + 0.9(0.9V_0(H) + 0.1V_0(M)), 5 + 0.9(0.7V_0(H) + 0.3V_0(M)) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c99bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Low Wealth (L)\n",
    "vL_func = lambda l, m: (max(-1 + 0.9*(0.8*l + 0.2*m), -1 + 0.9*(0.6*l + 0.4*m)))\n",
    "# For Medium Wealth (M)\n",
    "vM_func = lambda m, h: (max(3 + 0.9*(0.7*m + 0.3*h), 3 + 0.9*(0.5*m + 0.5*h)))\n",
    "# For High Walth (H)\n",
    "vH_func = lambda h, m: (max(5 + 0.9*(0.9*h + 0.1*m), 5 + 0.9*(0.7*h + 0.3*m)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35442968",
   "metadata": {},
   "source": [
    "Since $V_0(L) = V_0(M) = V_0(H) = 0$, the initial values are just the rewards.\n",
    "\n",
    ">$$\n",
    "V_1(L) = -1, \\quad V_1(M) = 3, \\quad V_1(H) = 5\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bccbc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V₁(L) = -1.0,  V₁(M) = 3.0,  V₁(H) = 5.0,\n"
     ]
    }
   ],
   "source": [
    "v1_L =  vL_func(v0_L, v0_M)\n",
    "v1_M =  vM_func(v0_M, v0_H)\n",
    "v1_H = vH_func(v0_H, v0_M)\n",
    "print(f\"V₁(L) = {v1_L},  V₁(M) = {v1_M},  V₁(H) = {v1_H},\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7689a850",
   "metadata": {},
   "source": [
    "#### **Policy Evaluation after Iteration 1**\n",
    "\n",
    "For **Low Wealth (L):**\n",
    "> $$\n",
    "Q(L, C) = -1 + 0.9(0.8(-1) + 0.2(3)) = -1.18\n",
    "$$\n",
    "\n",
    "> $$\n",
    "Q(L, A) = -1 + 0.9(0.6(-1) + 0.4(3)) = -0.46\n",
    "$$\n",
    "\n",
    "For **Medium Wealth (M):**\n",
    "\n",
    ">$$\n",
    "Q(M, C) = 3 + 0.9(0.7(3) + 0.3(5)) =  6.24\n",
    "$$\n",
    "\n",
    ">$$\n",
    "Q(M, A) = 3 + 0.9(0.5(3) + 0.5(5)) = 6.60\n",
    "$$\n",
    "\n",
    "For **High Wealth (H):**\n",
    "\n",
    ">$$\n",
    "Q(H, C) = 5 + 0.9(0.9(5) + 0.1(3)) = 9.32\n",
    "$$$\n",
    "\n",
    ">$$\n",
    "Q(H, A) = 5 + 0.9(0.7(5) + 0.3(3)) = 8.96\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f107d96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q(L,C) = -1.18\tQ(L,A) = -0.46\n",
      "Q(M,C) = 6.24\tQ(M,A) = 6.60\n",
      "Q(H,C) = 9.32\tQ(H,A) = 8.96\n"
     ]
    }
   ],
   "source": [
    "# Defning funcitons\n",
    "Q_LC = lambda l, m: -1 + 0.9*(0.8*l + 0.2*m)   # Q(L,C)\n",
    "Q_LA = lambda l, m: -1 + 0.9*(0.6*l + 0.4*m)   # Q(L,A)\n",
    "Q_MC = lambda m, h: 3 + 0.9*(0.7*m + 0.3*h)    # Q(M,C)\n",
    "Q_MA = lambda m, h: 3 + 0.9*(0.5*m + 0.5*h)    # Q(M,A)\n",
    "Q_HC = lambda h, m: 5 + 0.9*(0.9*h + 0.1*m)    # Q(H,C)    \n",
    "Q_HA = lambda h, m: 5 + 0.9*(0.7*h + 0.3*m)    # Q(H,A)\n",
    "\n",
    "Q_LC_1 = Q_LC(v1_L, v1_M)\n",
    "Q_LA_1 = Q_LA(v1_L, v1_M)\n",
    "Q_MC_1 = Q_MC(v1_M, v1_H)\n",
    "Q_MA_1 = Q_MA(v1_M, v1_H)\n",
    "Q_HC_1 = Q_HC(v1_H, v1_M)\n",
    "Q_HA_1 = Q_HA(v1_H, v1_M)\n",
    "\n",
    "print(f\"Q(L,C) = {Q_LC_1:.2f}\\tQ(L,A) = {Q_LA_1:.2f}\")\n",
    "print(f\"Q(M,C) = {Q_MC_1:.2f}\\tQ(M,A) = {Q_MA_1:.2f}\")\n",
    "print(f\"Q(H,C) = {Q_HC_1:.2f}\\tQ(H,A) = {Q_HA_1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e74772a",
   "metadata": {},
   "source": [
    "\n",
    "**Policy at Iteration 1:**\n",
    "- L → Aggressive (A)\n",
    "- M → Aggressive (A)\n",
    "- H → Conservative (C)\n",
    "\n",
    "\n",
    "#### **Iteration 2**\n",
    "\n",
    "Updating $V_2(s)$:\n",
    "\n",
    "For **Low Wealth (L):**\n",
    ">$$\n",
    "V_2(L) = \\max \\left[ -1 + 0.9(0.8(-1) + 0.2(3)), -1 + 0.9(0.6(-1) + 0.4(3)) \\right] = -0.46\n",
    "$$\n",
    "\n",
    "For **Medium Wealth (M):**\n",
    ">$$\n",
    "V_2(M) = \\max \\left[ 3 + 0.9(0.7(3) + 0.3(5)), 3 + 0.9(0.5(3) + 0.5(5)) \\right] = 6.60\n",
    "$$\n",
    "\n",
    "For **High Wealth (H):**\n",
    ">$$\n",
    "V_2(H) = \\max \\left[ 5 + 0.9(0.9(5) + 0.1(3)), 5 + 0.9(0.7(5) + 0.3(3)) \\right] = 9.32\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "152569ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V₂(L) = -0.46,  V₂(M) = 6.60,  V₂(H) = 9.32\n"
     ]
    }
   ],
   "source": [
    "v2_L = vL_func(v1_L, v1_M)\n",
    "v2_M = vM_func(v1_M, v1_H)\n",
    "v2_H = vH_func(v1_H, v1_M)\n",
    "print(f\"V₂(L) = {v2_L:.2f},  V₂(M) = {v2_M:.2f},  V₂(H) = {v2_H:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bd3210",
   "metadata": {},
   "source": [
    "#### **Policy Evaluation after Iteration 2**\n",
    "\n",
    "For **Low Wealth (L):**\n",
    "> $$\n",
    "Q(L, C) = -1 + 0.9(0.8(-0.46) + 0.2(6.6)) = -0.14\n",
    "$$\n",
    "\n",
    "> $$\n",
    "Q(L, A) = -1 + 0.9(0.6(-0.46) + 0.4(6.6)) = 1.13\n",
    "$$\n",
    "\n",
    "For **Medium Wealth (M):**\n",
    "\n",
    ">$$\n",
    "Q(M, C) = 3 + 0.9(0.7(6.6) + 0.3(9.32)) =  9.67\n",
    "$$\n",
    "\n",
    ">$$\n",
    "Q(M, A) = 3 + 0.9(0.5(6.6) + 0.5(9.32)) = 10.16\n",
    "$$\n",
    "\n",
    "For **High Wealth (H):**\n",
    "\n",
    ">$$\n",
    "Q(H, C) = 5 + 0.9(0.9(9.32) + 0.1(6.6)) = 13.14\n",
    "$$$\n",
    "\n",
    ">$$\n",
    "Q(H, A) = 5 + 0.9(0.7(9.32) + 0.3(6.6)) = 12.65\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c1b5116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q(L,C) = -0.14\tQ(L,A) = 1.13\n",
      "Q(M,C) = 9.67\tQ(M,A) = 10.16\n",
      "Q(H,C) = 13.14\tQ(H,A) = 12.65\n"
     ]
    }
   ],
   "source": [
    "Q_LC_2 = Q_LC(v2_L, v2_M)\n",
    "Q_LA_2 = Q_LA(v2_L, v2_M)\n",
    "Q_MC_2 = Q_MC(v2_M, v2_H)\n",
    "Q_MA_2 = Q_MA(v2_M, v2_H)\n",
    "Q_HC_2 = Q_HC(v2_H, v2_M)\n",
    "Q_HA_2 = Q_HA(v2_H, v2_M)\n",
    "\n",
    "print(f\"Q(L,C) = {Q_LC_2:.2f}\\tQ(L,A) = {Q_LA_2:.2f}\")\n",
    "print(f\"Q(M,C) = {Q_MC_2:.2f}\\tQ(M,A) = {Q_MA_2:.2f}\")\n",
    "print(f\"Q(H,C) = {Q_HC_2:.2f}\\tQ(H,A) = {Q_HA_2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91ee412",
   "metadata": {},
   "source": [
    "**Policy at Iteration 2:**\n",
    "- L → Aggressive (A)\n",
    "- M → Aggressive (A)\n",
    "- H → Conservative (C)\n",
    "\n",
    "#### **Iteration 3**\n",
    "\n",
    "Updating $V_3(s)$:\n",
    "\n",
    "For **Low Wealth (L):**\n",
    ">$$\n",
    "V_3(L) = \\max \\left[ -1 + 0.9(0.8(-0.46) + 0.2(6.6)), -1 + 0.9(0.6(-0.46) + 0.4(6.6)) \\right] = 1.13\n",
    "$$\n",
    "\n",
    "For **Medium Wealth (M):**\n",
    ">$$\n",
    "V_3(M) = \\max \\left[ 3 + 0.9(0.7(6.6) + 0.3(9.32)), 3 + 0.9(0.5(6.6) + 0.5(9.32)) \\right] = 10.16\n",
    "$$\n",
    "\n",
    "For **High Wealth (H):**\n",
    ">$$\n",
    "V_3(H) = \\max \\left[ 5 + 0.9(0.9(9.32) + 0.1(6.6)), 5 + 0.9(0.7(9.32) + 0.3(6.6)) \\right] = 13.14\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7177f7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V₃(L) = 1.13,  V₃(M) = 10.16,  V₃(H) = 13.14\n"
     ]
    }
   ],
   "source": [
    "v3_L = vL_func(v2_L, v2_M)\n",
    "v3_M = vM_func(v2_M, v2_H)\n",
    "v3_H = vH_func(v2_H, v2_M)\n",
    "print(f\"V₃(L) = {v3_L:.2f},  V₃(M) = {v3_M:.2f},  V₃(H) = {v3_H:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee32190",
   "metadata": {},
   "source": [
    "#### **Policy Change Analysis**\n",
    "\n",
    "From **Iteration 2 to Iteration 3**, let’s check the action values to determine if the policy changed.\n",
    "\n",
    "For **Low Wealth (L):**\n",
    "\n",
    ">$$\n",
    "Q(L, C) = -1 + 0.9(0.8(1.13) + 0.2(10.16)) = 1.64\n",
    "$$\n",
    "\n",
    ">$$\n",
    "Q(L, A) = -1 + 0.9(0.6(1.13) + 0.4(10.16)) = 3.27\n",
    "$$\n",
    "\n",
    "For **Medium Wealth (M):**\n",
    "\n",
    ">$$\n",
    "Q(M, C) = 3 + 0.9(0.7(10.16) + 0.3(13.14)) = 12.95\n",
    "$$\n",
    "\n",
    ">$$\n",
    "Q(M, A) = 3 + 0.9(0.7(10.16) + 0.5(13.14)) = 13.49\n",
    "$$\n",
    "\n",
    "For **High Wealth (H):**\n",
    "\n",
    ">$$\n",
    "Q(H, C) = 5 + 0.9(0.9(13.14) + 0.1(10.16)) = 16.56\n",
    "$$$\n",
    "\n",
    ">$$\n",
    "Q(H, A) = 5 + 0.9(0.7(13.14) + 0.3(10.16)) = 16.02\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "075d03d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q(L,C) = 1.64\tQ(L,A) = 3.27\n",
      "Q(M,C) = 12.95\tQ(M,A) = 13.49\n",
      "Q(H,C) = 16.56\tQ(H,A) = 16.02\n"
     ]
    }
   ],
   "source": [
    "Q_LC_3 = Q_LC(v3_L, v3_M)\n",
    "Q_LA_3 = Q_LA(v3_L, v3_M)\n",
    "Q_MC_3 = Q_MC(v3_M, v3_H)\n",
    "Q_MA_3 = Q_MA(v3_M, v3_H)\n",
    "Q_HC_3 = Q_HC(v3_H, v3_M)\n",
    "Q_HA_3 = Q_HA(v3_H, v3_M)\n",
    "\n",
    "print(f\"Q(L,C) = {Q_LC_3:.2f}\\tQ(L,A) = {Q_LA_3:.2f}\")\n",
    "print(f\"Q(M,C) = {Q_MC_3:.2f}\\tQ(M,A) = {Q_MA_3:.2f}\")\n",
    "print(f\"Q(H,C) = {Q_HC_3:.2f}\\tQ(H,A) = {Q_HA_3:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6becd-538b-4010-b4ed-c2e03c6c2e1a",
   "metadata": {},
   "source": [
    "Compare $Q(L, A), Q(L, C)$ and $Q(H, C),  Q(H, A)$, decide the policy updates:\n",
    "\n",
    "- **Low Wealth (L)** → Aggressive (A)\n",
    "- **Medium Wealth (M)** → Aggressive (A)\n",
    "- **High Wealth (H)** → Conservative (C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0e5695-a01b-4bcc-909b-582b5e64d068",
   "metadata": {},
   "source": [
    "### Summary: Policy Evolution Over Iterations\n",
    "\n",
    "| State  | Iteration 1 | Iteration 2 | Iteration 3 |\n",
    "|--------|------------|------------|------------|\n",
    "| Low      | Aggressive | Aggressive | Aggressive |\n",
    "| Medium   | Aggressive | Aggressive | Aggressive |\n",
    "| High     | Conservative | Conservative | Conservative |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myKernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
